# Техническое видение проекта

## Технологии

- **Python 3.11+** — язык разработки
- **uv** — менеджер зависимостей и виртуальных окружений
- **openai** — клиент для работы с LLM через OpenRouter API
- **aiogram** (версия 3.x) — фреймворк для Telegram-бота с использованием polling
- **make** — для команд сборки и запуска проекта
- **python-dotenv** — для загрузки переменных окружения из `.env` файла

### Примечания

- Используется async/await (aiogram 3.x требует асинхронного кода)
- На старте проекта база данных не используется — диалоги хранятся только в памяти

## Принцип разработки

1. **KISS (Keep It Simple, Stupid)** — простота прежде всего
2. **YAGNI (You Aren't Gonna Need It)** — реализуем только необходимое, ничего "на будущее"
3. **Минимализм** — никакого оверинжиниринга, только базовый функционал
4. **Быстрая проверка идеи** — сначала рабочий прототип, потом улучшения (если потребуется)
5. **Код должен быть понятным** — без лишних абстракций и усложнений
6. **Следование PEP 8** — стандартный стиль кода Python

### Что не делаем на старте

- Тесты — только рабочий прототип
- Линтеры и форматтеры — можно добавить позже, если потребуется
- Сложная архитектура — никаких лишних слоев абстракции
- Функции "на будущее" — только то, что нужно прямо сейчас

## Структура проекта

```
03-aidd/
├── docs/
│   ├── idea.md
│   └── vision.md
├── src/
│   ├── main.py              # Точка входа, запуск бота
│   ├── bot.py               # Обработка сообщений Telegram
│   └── llm.py               # Работа с LLM через OpenRouter
├── .env.example             # Пример файла с переменными окружения
├── .env                     # Файл с реальными переменными (в .gitignore)
├── .gitignore               # Игнорируемые файлы
├── pyproject.toml           # Зависимости через uv
├── Makefile                 # Команды для сборки и запуска
└── README.md                # Базовая документация
```

### Описание модулей

- **main.py** — точка входа, инициализация и запуск бота
- **bot.py** — логика Telegram-бота, обработчики сообщений от пользователей
- **llm.py** — работа с LLM через OpenRouter API

## Архитектура проекта

### Асинхронность

- **Все обработчики асинхронные** (async/await)
- **Параллельная обработка запросов:** один пользователь не блокирует других
- Aiogram использует event loop для параллельной обработки сообщений от разных пользователей
- Запросы к LLM выполняются асинхронно, не блокируя обработку других сообщений

### Поток работы

1. Пользователь отправляет сообщение в Telegram
2. `bot.py` получает сообщение через aiogram (асинхронно)
3. Для команды `/start`:
   - Выводится приветственное сообщение (async)
   - Очищается история диалога пользователя
4. Для обычного сообщения:
   - `bot.py` вызывает `llm.py` для получения ответа от LLM (async)
   - `llm.py` отправляет запрос к OpenRouter API с системным промптом и историей диалога (максимум 20 сообщений)
   - `llm.py` возвращает ответ боту
   - `bot.py` отправляет ответ пользователю в Telegram (async)
   - История диалога обновляется

### Хранение данных

- История диалога хранится в памяти в простом словаре: `{user_id: list[сообщений]}`
- Формат сообщений: `{"role": "user"/"assistant", "content": "..."}`
- Ограничение: хранится максимум 20 последних сообщений для каждого пользователя
- При команде `/start` история пользователя очищается
- Доступ к словарю должен быть потокобезопасным (обычный dict в Python достаточно безопасен для чтения/записи в async контексте при использовании aiogram)

### Модули и их взаимодействие

- **main.py** — инициализирует бота, запускает async polling
- **bot.py** — асинхронная обработка команд и сообщений Telegram, управление историей диалога
- **llm.py** — асинхронная отправка запросов к OpenRouter API, форматирование сообщений для LLM

## Модель данных

### История диалога

Структура данных:
```python
# Тип: dict[int, list[dict]]
# Ключ: user_id (int) - ID пользователя Telegram
# Значение: список сообщений

messages = [
    {"role": "user", "content": "текст сообщения"},
    {"role": "assistant", "content": "текст ответа"},
    ...
]
```

### Ограничения и правила

- Максимум 20 сообщений в истории для каждого пользователя
- При добавлении нового сообщения, если история превышает 20, удаляются самые старые сообщения
- Формат соответствует стандартному формату OpenAI API (role + content)
- Роли: `"user"` (сообщение пользователя) и `"assistant"` (ответ бота)
- Дополнительных данных о пользователях не хранится — только история диалога

## Работа с LLM

### Провайдер и модель

- **Провайдер:** OpenRouter API
- **Модель:** `openai/gpt-oss-20b:free`
- **Base URL:** `https://openrouter.ai/api/v1`
- **Клиент:** стандартный `openai` Python client

### Системный промпт

- Роль: **Персональный тренер по фитнесу**
- Системный промпт задается один раз при инициализации
- Добавляется в каждый запрос к LLM как системное сообщение

### Формат запроса

Каждый запрос к LLM включает:
1. Системное сообщение с промптом роли
2. История диалога (до 20 последних сообщений)
3. Новое сообщение пользователя

### Параметры запроса

- **temperature:** 0.7 (баланс между креативностью и предсказуемостью)
- **max_tokens:** не ограничивается (или стандартное значение API)
- Другие параметры — значения по умолчанию

## Сценарии работы

### Сценарий 1: Первый запуск (команда /start)

1. Пользователь отправляет `/start` в Telegram
2. Бот выводит приветственное сообщение: "Привет! Я твой персональный тренер по фитнесу. Чем могу помочь?"
3. История диалога для пользователя очищается (или создается пустая запись)

### Сценарий 2: Обычный диалог

1. Пользователь отправляет текстовое сообщение
2. Бот добавляет сообщение пользователя в историю диалога
3. Бот вызывает LLM с:
   - Системным промптом (роль тренера)
   - Историей диалога (до 20 сообщений)
   - Новым сообщением пользователя
4. Получает ответ от LLM
5. Отправляет ответ пользователю в Telegram
6. Добавляет ответ ассистента в историю диалога
7. Если история превышает 20 сообщений, удаляются самые старые сообщения

### Сценарий 3: Нетекстовое сообщение

1. Пользователь отправляет фото, голосовое сообщение или другой тип контента
2. Бот отвечает текстовым сообщением: "Пожалуйста, отправьте текстовое сообщение"

### Поддерживаемые команды

- `/start` — приветствие и очистка истории диалога
- Другие команды не обрабатываются (только текстовые сообщения)

## Подход к конфигурированию

### Переменные окружения (.env файл)

**Обязательные:**
- `TELEGRAM_BOT_TOKEN` — токен Telegram бота
- `OPENROUTER_API_KEY` — API ключ для OpenRouter

**Опциональные (с значениями по умолчанию):**
- `OPENROUTER_MODEL` — модель LLM (по умолчанию: `openai/gpt-oss-20b:free`)
- `SYSTEM_PROMPT` — системный промпт для роли персонального тренера по фитнесу
- `TEMPERATURE` — параметр температуры для LLM (по умолчанию: `0.7`)
- `MAX_HISTORY_MESSAGES` — максимальное количество сообщений в истории диалога (по умолчанию: `20`)

### Файлы конфигурации

- `.env` — реальные переменные окружения (в .gitignore)
- `.env.example` — пример файла с описанием всех переменных и их назначением

### Загрузка конфигурации

- Использовать `python-dotenv` для загрузки переменных из `.env` файла
- Загрузка происходит при старте приложения в `main.py`
- Значения по умолчанию используются, если переменная не задана в `.env`

## Подход к логгированию

### Использование стандартного модуля

- **Модуль:** стандартный `logging` из Python (без дополнительных зависимостей)
- **Вывод:** консоль (stdout)
- **Формат:** простой текстовый формат с timestamp

### Уровни логирования

- **INFO** — основная информация (запуск/остановка бота, получение сообщений)
- **ERROR** — ошибки (проблемы с API, исключения)

### Что логировать

- Запуск и остановка бота
- Получение сообщений от пользователей (user_id, тип сообщения)
- Вызовы LLM (только факт вызова, без запросов и ответов)
- Ошибки при работе с Telegram API или OpenRouter API

### Что не логировать

- Содержимое сообщений пользователей
- Запросы к LLM (промпты, история диалога)
- Ответы от LLM
- Метрики и аналитику

### Принцип

Минимальное логирование только для понимания состояния бота и отслеживания ошибок. Без деталей содержимого сообщений и ответов LLM.

